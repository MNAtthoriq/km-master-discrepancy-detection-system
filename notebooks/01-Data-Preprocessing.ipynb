{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2472415d",
   "metadata": {},
   "source": [
    "# **KM Master Discrepancy Detection System - Data Preprocessing**\n",
    "\n",
    "![Python Code](https://img.shields.io/badge/Python-Code-blue?logo=python&logoColor=white)\n",
    "![Sheets API](https://img.shields.io/badge/Google_Sheets-API-34A853?logo=googlesheets&logoColor=white)\n",
    "\n",
    "### **Project Context**\n",
    "\n",
    "KM Master represents the **round-trip distance** between Operating Points (OP) and Stores, which is critical for calculating **UJP** (Uang Jalan Pengiriman - transportation costs).\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Underestimated distances** → Operational problems, driver dissatisfaction\n",
    "- **Overestimated distances** → Fraud opportunities, inflated costs\n",
    "\n",
    "With **thousands of stores**, manually validating all KM Master entries is impractical. The operations team needs to **prioritize** which entries to validate first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bdb9a2",
   "metadata": {},
   "source": [
    "# **Setup and Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233b71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added km-master-discrepancy-detection-system\\notebooks\\..\\src to sys.path\n"
     ]
    }
   ],
   "source": [
    "# setup source path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# add source directory to python path for custom modules\n",
    "src_path = os.path.join(os.getcwd(), \"..\", \"src\")\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    print(f\"Added {src_path[34:]} to sys.path\")\n",
    "else:\n",
    "    print(f\"{src_path[34:]} already in sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25efd16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:26:57 - __main__ - INFO - Hiding numeric values with '*' symbol\n"
     ]
    }
   ],
   "source": [
    "# initialize configuration and environment variables\n",
    "import config\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(config.ENV_PATH)\n",
    "\n",
    "# set hide_values parameter\n",
    "# config.HIDE_VALUES = False  # uncomment to show numeric values\n",
    "\n",
    "# import custom modules\n",
    "from data_preprocessing import convert_to_op_code, correct_scientific_notation\n",
    "from utils import setup_logging, mask_numeric_value, DataTracker\n",
    "\n",
    "# import common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "\n",
    "# setup logging\n",
    "setup_logging()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# display configuration\n",
    "if config.HIDE_VALUES:\n",
    "    logger.info(f\"Hiding numeric values with '*' symbol\")\n",
    "else:\n",
    "    logger.info(\"Showing numeric values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b7d71",
   "metadata": {},
   "source": [
    "# **Data**\n",
    "\n",
    "### **Data Preprocessing**\n",
    "\n",
    "This notebook cleans and merges two data sources:\n",
    "\n",
    "1. **Operational Data**\n",
    "   - Historical delivery distances (KM Tempuh)\n",
    "   \n",
    "2. **Master Zona Data**\n",
    "   - Store master information\n",
    "\n",
    "**Output:**  \n",
    "Clean, validated dataset ready for analysis\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Disclaimer:** <br>Due to confidentiality, actual data **is not included** in this repository. <br>Some values are replaced with the `*` symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f9e4d",
   "metadata": {},
   "source": [
    "## **A. Operational Data**\n",
    "\n",
    "### **Key Columns:**\n",
    "  - `Tgl SLA` - Delivery date\n",
    "  - `OP` - Operating Point\n",
    "  - `Nomor SPJ` - Delivery records / Waybill. One `SPJ` may contain several `Toko`\n",
    "  - `Toko` - Store code\n",
    "  - `KM Tempuh` - Actual distance traveled (round-trip) for each `SPJ`\n",
    "  - `KM Master` - Master distance (round-trip) for each `Toko`\n",
    "  - `KM Max` - Maximum value of `KM Master` for each `Toko` for each `SPJ`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b354d",
   "metadata": {},
   "source": [
    "### **1. Load Data & Start Tracker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1d5288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:27:02 - __main__ - INFO - Loaded *,***,*** rows of operational data in 4.69 secs\n"
     ]
    }
   ],
   "source": [
    "# define path for operational data\n",
    "op_data_fns = [\"1. Operational Data - Januari 2025.csv\",\n",
    "               \"2. Operational Data - Februari 2025.csv\",\n",
    "               \"3. Operational Data - Maret 2025.csv\",\n",
    "               \"4. Operational Data - April 2025.csv\",\n",
    "               \"5. Operational Data - Mei 2025.csv\",\n",
    "               \"6. Operational Data - Juni 2025.csv\",\n",
    "               \"7. Operational Data - Juli 2025.csv\",\n",
    "               \"8. Operational Data - Agustus 2025.csv\"]\n",
    "\n",
    "op_data_paths = [os.path.join(config.DATA_PATH, \"raw\", filename) for filename in op_data_fns]\n",
    "\n",
    "# read operational data\n",
    "start_time = time.time()\n",
    "df_op_data = pd.concat([pd.read_csv(path, sep=';', low_memory=False, dtype=str) for path in op_data_paths], ignore_index=True)\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "logger.info(f\"Loaded {mask_numeric_value(f'{len(df_op_data):,}')} rows of operational data in {load_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c34eb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:27:02 - utils - INFO - Initialized DataTracker for: [Operational Data]\n",
      "2025-12-16 06:27:02 - utils - INFO - [Operational Data] Step: Initial Rows | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 100.00% | Step Time: 0.00s | Cumulative Time: 0.00s\n"
     ]
    }
   ],
   "source": [
    "# track preprocessing operational data\n",
    "tracker_op_data = DataTracker(\"Operational Data\")\n",
    "tracker_op_data.track(df_op_data, step_name=\"Initial Rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fd4c4",
   "metadata": {},
   "source": [
    "### **2. Remove Empty or Duplicated Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe71aa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:27:04 - utils - INFO - [Operational Data] Step: Remove Empty Rows | Counts: *,***,*** | Change: -***,*** (-8.29%) | Retention: 91.71% | Step Time: 1.61s | Cumulative Time: 1.62s\n",
      "2025-12-16 06:27:07 - utils - INFO - [Operational Data] Step: Remove Duplicated Rows | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 91.71% | Step Time: 2.91s | Cumulative Time: 4.52s\n"
     ]
    }
   ],
   "source": [
    "# drop rows with all NaN value\n",
    "df_op_data = df_op_data.dropna(how='all') \n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Remove Empty Rows\")\n",
    "\n",
    "# drop rows with duplicate value\n",
    "df_op_data = df_op_data.drop_duplicates()\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Remove Duplicated Rows\")\n",
    "\n",
    "# validate if there are any null value\n",
    "# it will help to identify data quality issues earlier than using dropna(how='any')\n",
    "if df_op_data.isna().sum().sum() > 0:\n",
    "    logger.exception(\"There are null values in the operational data\")\n",
    "    raise ValueError(\"There are null values in the operational data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f593c0a",
   "metadata": {},
   "source": [
    "### **3. Convert Operating Point (OP) name to OP Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8bc1d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:27:08 - data_preprocessing - INFO - Converting OP names to OP codes using method: complete\n",
      "2025-12-16 06:27:08 - google_sheets_io - INFO - Loading Google Sheets from URL: https://docs.google.com/spread [Redacted]...\n",
      "2025-12-16 06:27:08 - google_sheets_io - INFO - Credentials loaded successfully\n",
      "2025-12-16 06:27:08 - google_sheets_io - INFO - Google Sheets API authorized\n",
      "2025-12-16 06:27:09 - google_sheets_io - INFO - Sheet opened successfully\n",
      "2025-12-16 06:27:10 - data_preprocessing - INFO - Loaded *** OP codes from sheets Master Kode OP\n",
      "2025-12-16 06:27:16 - data_preprocessing - INFO - All OP names successfully converted to OP codes\n",
      "2025-12-16 06:27:17 - utils - INFO - [Operational Data] Step: Convert OP Name to OP Code | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 91.71% | Step Time: 10.30s | Cumulative Time: 14.82s\n"
     ]
    }
   ],
   "source": [
    "# convert OP name to OP code\n",
    "# example: \"Operating Point Satu\" → \"OP1\"\n",
    "# this function correct it using data from google sheets\n",
    "df_op_data = convert_to_op_code(df_op_data, sheets_url=os.getenv('SHEETS_URL'))\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Convert OP Name to OP Code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9c37c",
   "metadata": {},
   "source": [
    "### **4. Remove Ignored OPs and Stores**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619e1f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:27:17 - utils - INFO - [Operational Data] Step: Remove Rows with Ignored OP | Counts: *,***,*** | Change: -**,*** (-0.30%) | Retention: 91.44% | Step Time: 0.51s | Cumulative Time: 15.34s\n",
      "2025-12-16 06:27:19 - utils - INFO - [Operational Data] Step: Remove Rows with Ignored Store | Counts: *,***,*** | Change: -*,*** (-0.03%) | Retention: 91.41% | Step Time: 1.57s | Cumulative Time: 16.90s\n"
     ]
    }
   ],
   "source": [
    "# remove ignored OPs\n",
    "# like testing OP, new OP, etc\n",
    "exclude_ops = os.getenv('EXCLUDE_OPS').split(',')\n",
    "df_op_data = df_op_data[~df_op_data['OP'].isin(exclude_ops)]\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Remove Rows with Ignored OP\")\n",
    "\n",
    "# remove ignored stores\n",
    "# like testing store, standby store, etc\n",
    "exclude_stores = re.compile(rf\"{os.getenv('EXCLUDE_STORES')}\")\n",
    "df_op_data = df_op_data[~df_op_data['Toko'].str.contains(exclude_stores, na=False)]\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Remove Rows with Ignored Store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9ee1a",
   "metadata": {},
   "source": [
    "### **5. Correct Scientific Notation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2165d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:27:19 - data_preprocessing - INFO - Starting scientific notation correction for store codes\n",
      "2025-12-16 06:27:19 - google_sheets_io - INFO - Loading Google Sheets from URL: https://docs.google.com/spread [Redacted]...\n",
      "2025-12-16 06:27:19 - google_sheets_io - INFO - Credentials loaded successfully\n",
      "2025-12-16 06:27:19 - google_sheets_io - INFO - Google Sheets API authorized\n",
      "2025-12-16 06:27:20 - google_sheets_io - INFO - Sheet opened successfully\n",
      "2025-12-16 06:27:20 - data_preprocessing - INFO - Loaded *** store mappings from sheets Master Saintifik Toko\n",
      "2025-12-16 06:27:23 - data_preprocessing - INFO - Found *,*** stores with comma delimiter, * with period delimiter\n",
      "2025-12-16 06:27:58 - data_preprocessing - INFO - All store codes successfully corrected.\n",
      "2025-12-16 06:27:58 - utils - INFO - [Operational Data] Step: Correct Scientific Notation | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 91.41% | Step Time: 39.00s | Cumulative Time: 55.91s\n"
     ]
    }
   ],
   "source": [
    "# correct scientific notation\n",
    "# excel sometimes convert store codes like \"8E34\" to \"8.00E+34\"\n",
    "# this function correct it using data from google sheets\n",
    "df_op_data = correct_scientific_notation(df_op_data, sheets_url=os.getenv('SHEETS_URL'))\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Correct Scientific Notation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04140ced",
   "metadata": {},
   "source": [
    "### **6. Convert Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "117b0065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:08 - utils - INFO - [Operational Data] Step: Convert Data Type | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 91.41% | Step Time: 9.81s | Cumulative Time: 65.72s\n"
     ]
    }
   ],
   "source": [
    "# convert data type\n",
    "for col in ['KM Tempuh', 'KM Master', 'KM Max']:\n",
    "  # remove '.' and ',' symbols\n",
    "  df_op_data[col] = df_op_data[col].str.replace(r'[.,]', '', regex=True)\n",
    "  # convert to numeric\n",
    "  df_op_data[col] = pd.to_numeric(df_op_data[col], errors='coerce')\n",
    "  # raise error if there is NaN data\n",
    "  if df_op_data[col].isna().any():\n",
    "    logger.error(f\"Column {col} contains NaN values\")\n",
    "    raise ValueError(f\"Column {col} contains NaN values\")\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Convert Data Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c393b6",
   "metadata": {},
   "source": [
    "### **7. Remove Rows with Invalid KM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6825107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:08 - utils - INFO - [Operational Data] Step: Remove Rows with Invalid KM | Counts: *,***,*** | Change: -*** (-0.02%) | Retention: 91.39% | Step Time: 0.33s | Cumulative Time: 66.05s\n"
     ]
    }
   ],
   "source": [
    "# remove rows with KM Tempuh < 1\n",
    "df_op_data = df_op_data[df_op_data['KM Tempuh'] >= 1]\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Remove Rows with Invalid KM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e0cb0",
   "metadata": {},
   "source": [
    "### **8. Calculate Deviation & Save Unique OP + Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544d83af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:09 - utils - INFO - [Operational Data] Step: Calculate Deviation & Save Unique OP + Store | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 91.39% | Step Time: 0.79s | Cumulative Time: 66.83s\n"
     ]
    }
   ],
   "source": [
    "# add column KM Deviation\n",
    "df_op_data['KM Deviation (%)'] = (df_op_data['KM Tempuh'] - df_op_data['KM Max']) / df_op_data['KM Max'] * 100\n",
    "\n",
    "# save tuple of unique OP and store for preprocessing master zona data\n",
    "unique_pairs = df_op_data[['OP', 'Toko']].drop_duplicates()\n",
    "unique_op_store_op_data = tuple(map(tuple, unique_pairs.values))\n",
    "\n",
    "tracker_op_data.track(df_op_data, step_name=\"Calculate Deviation & Save Unique OP + Store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1278fc4",
   "metadata": {},
   "source": [
    "### **Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5faf5e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:09 - utils - INFO - [Operational Data] DataTracker summary generated for 10 steps.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change (%)</th>\n",
       "      <th>Retained (%)</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>Cumulative Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial Rows</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remove Empty Rows</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>-***,***</td>\n",
       "      <td>-8.29</td>\n",
       "      <td>91.71</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remove Duplicated Rows</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>91.71</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convert OP Name to OP Code</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>91.71</td>\n",
       "      <td>10.30</td>\n",
       "      <td>14.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remove Rows with Ignored OP</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>-**,***</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>91.44</td>\n",
       "      <td>0.51</td>\n",
       "      <td>15.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Remove Rows with Ignored Store</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>-*,***</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>91.41</td>\n",
       "      <td>1.57</td>\n",
       "      <td>16.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Correct Scientific Notation</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>91.41</td>\n",
       "      <td>39.00</td>\n",
       "      <td>55.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Convert Data Type</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>91.41</td>\n",
       "      <td>9.81</td>\n",
       "      <td>65.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Remove Rows with Invalid KM</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>-***</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>91.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>66.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Calculate Deviation &amp; Save Unique OP + Store</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>91.39</td>\n",
       "      <td>0.79</td>\n",
       "      <td>66.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Step     Counts    Change  \\\n",
       "0                                  Initial Rows  *,***,***        +0   \n",
       "1                             Remove Empty Rows  *,***,***  -***,***   \n",
       "2                        Remove Duplicated Rows  *,***,***        +0   \n",
       "3                    Convert OP Name to OP Code  *,***,***        +0   \n",
       "4                   Remove Rows with Ignored OP  *,***,***   -**,***   \n",
       "5                Remove Rows with Ignored Store  *,***,***    -*,***   \n",
       "6                   Correct Scientific Notation  *,***,***        +0   \n",
       "7                             Convert Data Type  *,***,***        +0   \n",
       "8                   Remove Rows with Invalid KM  *,***,***      -***   \n",
       "9  Calculate Deviation & Save Unique OP + Store  *,***,***        +0   \n",
       "\n",
       "  Change (%) Retained (%) Duration (s) Cumulative Time (s)  \n",
       "0      +0.00       100.00         0.00                0.00  \n",
       "1      -8.29        91.71         1.61                1.62  \n",
       "2      +0.00        91.71         2.91                4.52  \n",
       "3      +0.00        91.71        10.30               14.82  \n",
       "4      -0.30        91.44         0.51               15.34  \n",
       "5      -0.03        91.41         1.57               16.90  \n",
       "6      +0.00        91.41        39.00               55.91  \n",
       "7      +0.00        91.41         9.81               65.72  \n",
       "8      -0.02        91.39         0.33               66.05  \n",
       "9      +0.00        91.39         0.79               66.83  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary\n",
    "tracker_op_data.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa9632",
   "metadata": {},
   "source": [
    "## **B. Master Zona Data**\n",
    "\n",
    "### **Key Columns:**\n",
    "  - `OP` - Operating Point\n",
    "  - `Toko` - Store code\n",
    "  - `KM Master` - Master distance (round-trip) for each `Toko`\n",
    "  - `Kode Zona` - Zone code\n",
    "  - `Kecamatan`, `Kota`, `Provinsi` - Geographic info\n",
    "  - `Status Toko` - Store active status (1=active, 0=inactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0213f18",
   "metadata": {},
   "source": [
    "### **1. Load Data & Start Tracker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "354dd9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:09 - __main__ - INFO - Loaded **,*** rows of master zona data in 0.14 secs\n"
     ]
    }
   ],
   "source": [
    "# master zona data\n",
    "mz_data_fn = \"Master Zona Data.csv\"\n",
    "mz_data_path = os.path.join(config.DATA_PATH, \"raw\", mz_data_fn)\n",
    "\n",
    "# read master zona data\n",
    "start_time = time.time()\n",
    "df_mz_data = pd.read_csv(mz_data_path, sep=';', low_memory=False, dtype=str, encoding='latin-1')\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "logger.info(f\"Loaded {mask_numeric_value(f'{len(df_mz_data):,}')} rows of master zona data in {load_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b99b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:09 - utils - INFO - Initialized DataTracker for: [Master Zona Data]\n",
      "2025-12-16 06:28:09 - utils - INFO - [Master Zona Data] Step: Initial Rows | Counts: **,*** | Change: +0 (+0.00%) | Retention: 100.00% | Step Time: 0.00s | Cumulative Time: 0.00s\n"
     ]
    }
   ],
   "source": [
    "# track preprocessing master zona data\n",
    "tracker_mz_data = DataTracker(\"Master Zona Data\")\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Initial Rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f4470",
   "metadata": {},
   "source": [
    "### **2. Remove Empty Rows, Rows Without Customer, or Duplicated Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:09 - utils - INFO - [Master Zona Data] Step: Remove Empty Rows | Counts: **,*** | Change: +0 (+0.00%) | Retention: 100.00% | Step Time: 0.06s | Cumulative Time: 0.06s\n",
      "2025-12-16 06:28:09 - utils - INFO - [Master Zona Data] Step: Remove Rows Without Customer | Counts: **,*** | Change: -* (-0.01%) | Retention: 99.99% | Step Time: 0.02s | Cumulative Time: 0.08s\n",
      "2025-12-16 06:28:09 - utils - INFO - [Master Zona Data] Step: Remove Duplicated Rows | Counts: **,*** | Change: +0 (+0.00%) | Retention: 99.99% | Step Time: 0.05s | Cumulative Time: 0.13s\n"
     ]
    }
   ],
   "source": [
    "# drop rows with all NaN value\n",
    "df_mz_data = df_mz_data.dropna(how='all')\n",
    "\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Remove Empty Rows\")\n",
    "\n",
    "# drop rows with NaN customer (no customer = no transaction)\n",
    "df_mz_data = df_mz_data.dropna(subset=['Customer'])\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Remove Rows Without Customer\")\n",
    "\n",
    "# drop rows with duplicate value\n",
    "df_mz_data = df_mz_data.drop_duplicates()\n",
    "\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Remove Duplicated Rows\")\n",
    "\n",
    "# validate if there are any null value\n",
    "# it will help to identify data quality issues earlier than using dropna(how='any')\n",
    "if df_mz_data.isna().sum().sum() > 0:\n",
    "    logger.exception(\"There are null values in the master zona data\")\n",
    "    raise ValueError(\"There are null values in the master zona data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824233cc",
   "metadata": {},
   "source": [
    "### **3. Convert OP Name to OP Code using Partial Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32df8a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:09 - data_preprocessing - INFO - Converting OP names to OP codes using method: partial\n",
      "2025-12-16 06:28:09 - google_sheets_io - INFO - Loading Google Sheets from URL: https://docs.google.com/spread [Redacted]...\n",
      "2025-12-16 06:28:09 - google_sheets_io - INFO - Credentials loaded successfully\n",
      "2025-12-16 06:28:09 - google_sheets_io - INFO - Google Sheets API authorized\n",
      "2025-12-16 06:28:10 - google_sheets_io - INFO - Sheet opened successfully\n",
      "2025-12-16 06:28:11 - data_preprocessing - INFO - Loaded *** OP codes from sheets Master Kode OP\n",
      "2025-12-16 06:28:11 - data_preprocessing - INFO - Dropped *,*** rows with unmapped OP codes (10.31%%)\n",
      "2025-12-16 06:28:11 - utils - INFO - [Master Zona Data] Step: Convert OP Name to OP Code | Counts: **,*** | Change: -*,*** (-10.31%) | Retention: 89.68% | Step Time: 1.85s | Cumulative Time: 1.98s\n"
     ]
    }
   ],
   "source": [
    "# convert OP name to OP code with partial method\n",
    "# use 'partial' method: drops rows with unmapped OPs instead of raising error\n",
    "# reason: Master Zona may contain OPs outside our Operational data scope\n",
    "df_mz_data = convert_to_op_code(df_mz_data, sheets_url=os.getenv(\"SHEETS_URL\"), method='partial')\n",
    "\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Convert OP Name to OP Code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18aa748",
   "metadata": {},
   "source": [
    "### **4. Correct Scientific Notation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa86ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:11 - data_preprocessing - INFO - Starting scientific notation correction for store codes\n",
      "2025-12-16 06:28:11 - google_sheets_io - INFO - Loading Google Sheets from URL: https://docs.google.com/spread [Redacted]...\n",
      "2025-12-16 06:28:11 - google_sheets_io - INFO - Credentials loaded successfully\n",
      "2025-12-16 06:28:11 - google_sheets_io - INFO - Google Sheets API authorized\n",
      "2025-12-16 06:28:12 - google_sheets_io - INFO - Sheet opened successfully\n",
      "2025-12-16 06:28:12 - data_preprocessing - INFO - Loaded *** store mappings from sheets Master Saintifik Toko\n",
      "2025-12-16 06:28:13 - data_preprocessing - INFO - Found ** stores with comma delimiter, ** with period delimiter\n",
      "2025-12-16 06:28:13 - data_preprocessing - INFO - All store codes successfully corrected.\n",
      "2025-12-16 06:28:13 - utils - INFO - [Master Zona Data] Step: Correct Scientific Notation | Counts: **,*** | Change: +0 (+0.00%) | Retention: 89.68% | Step Time: 2.18s | Cumulative Time: 4.16s\n"
     ]
    }
   ],
   "source": [
    "# correct scientific notation\n",
    "df_mz_data = correct_scientific_notation(df_mz_data, sheets_url=os.getenv(\"SHEETS_URL\"))\n",
    "\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Correct Scientific Notation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d20885",
   "metadata": {},
   "source": [
    "### **5. Filter to Operational Scope**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860c272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:13 - utils - INFO - [Master Zona Data] Step: Filter to Operational Scope | Counts: **,*** | Change: -**,*** (-36.55%) | Retention: 56.90% | Step Time: 0.33s | Cumulative Time: 4.48s\n"
     ]
    }
   ],
   "source": [
    "# keep only stores that exist in operational data\n",
    "df_mz_data = df_mz_data[df_mz_data[['OP', 'Toko']].apply(tuple, axis=1).isin(unique_op_store_op_data)]\n",
    "\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Filter to Operational Scope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039b011",
   "metadata": {},
   "source": [
    "### **6. Convert Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c34a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:14 - utils - INFO - [Master Zona Data] Step: Convert Data Type | Counts: **,*** | Change: +0 (+0.00%) | Retention: 56.90% | Step Time: 0.04s | Cumulative Time: 4.53s\n"
     ]
    }
   ],
   "source": [
    "# convert data type\n",
    "for col in ['KM Master']:\n",
    "  # remove '.' and ',' symbols\n",
    "  df_mz_data[col] = df_mz_data[col].str.replace(r'[.,]', '', regex=True)\n",
    "  # convert to numeric\n",
    "  df_mz_data[col] = pd.to_numeric(df_mz_data[col], errors='coerce')\n",
    "  # raise error if there is NaN data\n",
    "  if df_mz_data[col].isna().any():\n",
    "    logger.error(f\"Column {col} contains NaN values\")\n",
    "    raise ValueError(f\"Column {col} contains NaN values\")\n",
    "\n",
    "tracker_mz_data.track(df_mz_data, step_name=\"Convert Data Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58193878",
   "metadata": {},
   "source": [
    "### **Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f674d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:14 - utils - INFO - [Master Zona Data] DataTracker summary generated for 8 steps.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change (%)</th>\n",
       "      <th>Retained (%)</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>Cumulative Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial Rows</td>\n",
       "      <td>**,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remove Empty Rows</td>\n",
       "      <td>**,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remove Rows Without Customer</td>\n",
       "      <td>**,***</td>\n",
       "      <td>-*</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>99.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remove Duplicated Rows</td>\n",
       "      <td>**,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>99.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Convert OP Name to OP Code</td>\n",
       "      <td>**,***</td>\n",
       "      <td>-*,***</td>\n",
       "      <td>-10.31</td>\n",
       "      <td>89.68</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Correct Scientific Notation</td>\n",
       "      <td>**,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>89.68</td>\n",
       "      <td>2.18</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Filter to Operational Scope</td>\n",
       "      <td>**,***</td>\n",
       "      <td>-**,***</td>\n",
       "      <td>-36.55</td>\n",
       "      <td>56.90</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Convert Data Type</td>\n",
       "      <td>**,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>56.90</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Step  Counts   Change Change (%) Retained (%)  \\\n",
       "0                  Initial Rows  **,***       +0      +0.00       100.00   \n",
       "1             Remove Empty Rows  **,***       +0      +0.00       100.00   \n",
       "2  Remove Rows Without Customer  **,***       -*      -0.01        99.99   \n",
       "3        Remove Duplicated Rows  **,***       +0      +0.00        99.99   \n",
       "4    Convert OP Name to OP Code  **,***   -*,***     -10.31        89.68   \n",
       "5   Correct Scientific Notation  **,***       +0      +0.00        89.68   \n",
       "6   Filter to Operational Scope  **,***  -**,***     -36.55        56.90   \n",
       "7             Convert Data Type  **,***       +0      +0.00        56.90   \n",
       "\n",
       "  Duration (s) Cumulative Time (s)  \n",
       "0         0.00                0.00  \n",
       "1         0.06                0.06  \n",
       "2         0.02                0.08  \n",
       "3         0.05                0.13  \n",
       "4         1.85                1.98  \n",
       "5         2.18                4.16  \n",
       "6         0.33                4.48  \n",
       "7         0.04                4.53  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary\n",
    "tracker_mz_data.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d8077",
   "metadata": {},
   "source": [
    "## **C. All Data**\n",
    "\n",
    "### **Merge Strategy**\n",
    "  - Using `inner join` because we only analyze OP and Stores in both Operational and Master Zona data\n",
    "  - Join keys using `OP` and `Toko` because there is no one distinct column. It is because one `OP` may has several `Toko` and vice versa\n",
    "  - Because both data has `KM Master` column, only `KM Master` column from Master Zona data will be used. It is because in Operational data, there is may outdated `KM Master` value in past"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf1bb8",
   "metadata": {},
   "source": [
    "### **1. Merged Data & Start Tracker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3996adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:16 - __main__ - INFO - Combined *,***,*** rows of operational data and master zona data in 2.26 secs\n"
     ]
    }
   ],
   "source": [
    "# merged data\n",
    "start_time = time.time()\n",
    "df_all_data = pd.merge(\n",
    "                df_op_data[[col for col in df_op_data.columns if col != \"KM Master\"]],\n",
    "                df_mz_data[\n",
    "                    ['OP','Toko','KM Master','Kode Zona',\n",
    "                     'Kecamatan','Kota','Provinsi','Status Toko']],\n",
    "                how='inner', on=['OP', 'Toko']\n",
    "                )\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "logger.info(f\"Combined {mask_numeric_value(f'{len(df_all_data):,}')} rows of operational data and master zona data in {load_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c7aebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:16 - utils - INFO - Initialized DataTracker for: [All Data]\n",
      "2025-12-16 06:28:16 - utils - INFO - [All Data] Step: Initial Rows | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 100.00% | Step Time: 0.00s | Cumulative Time: 0.00s\n"
     ]
    }
   ],
   "source": [
    "# track preprocessing merged data\n",
    "tracker_all_data = DataTracker(\"All Data\")\n",
    "tracker_all_data.track(df_all_data, step_name=\"Initial Rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8551483",
   "metadata": {},
   "source": [
    "### **2. Remove Empty or Duplicated Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:18 - utils - INFO - [All Data] Step: Remove Empty Rows | Counts: *,***,*** | Change: +0 (+0.00%) | Retention: 100.00% | Step Time: 2.20s | Cumulative Time: 2.20s\n",
      "2025-12-16 06:28:23 - utils - INFO - [All Data] Step: Remove Duplicated Rows | Counts: *,***,*** | Change: -** (-0.00%) | Retention: 100.00% | Step Time: 5.28s | Cumulative Time: 7.48s\n"
     ]
    }
   ],
   "source": [
    "# drop rows with all NaN value\n",
    "df_all_data = df_all_data.dropna(how='all')\n",
    "\n",
    "tracker_all_data.track(df_all_data, step_name=\"Remove Empty Rows\")\n",
    "\n",
    "# drop rows with duplicate value\n",
    "df_all_data = df_all_data.drop_duplicates()\n",
    "\n",
    "tracker_all_data.track(df_all_data, step_name=\"Remove Duplicated Rows\")\n",
    "\n",
    "# validate if there are any null value\n",
    "# it will help to identify data quality issues earlier than using dropna(how='any')\n",
    "if df_all_data.isna().sum().sum() > 0:\n",
    "    logger.exception(\"There are null values in the all data\")\n",
    "    raise ValueError(\"There are null values in the all data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe9260",
   "metadata": {},
   "source": [
    "### **3. Remove Inactive Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f59806a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:26 - utils - INFO - [All Data] Step: Remove Inactive Store | Counts: *,***,*** | Change: -*,*** (-0.13%) | Retention: 99.87% | Step Time: 2.61s | Cumulative Time: 10.09s\n"
     ]
    }
   ],
   "source": [
    "# filter status toko = 1\n",
    "df_all_data = df_all_data[df_all_data['Status Toko'] == '1']\n",
    "\n",
    "# drop column Status Toko\n",
    "df_all_data = df_all_data.drop(columns=['Status Toko'])\n",
    "\n",
    "tracker_all_data.track(df_all_data, step_name=\"Remove Inactive Store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162da614",
   "metadata": {},
   "source": [
    "### **Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5add674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:26 - utils - INFO - [All Data] DataTracker summary generated for 4 steps.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change (%)</th>\n",
       "      <th>Retained (%)</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>Cumulative Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial Rows</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remove Empty Rows</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remove Duplicated Rows</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>-**</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.28</td>\n",
       "      <td>7.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remove Inactive Store</td>\n",
       "      <td>*,***,***</td>\n",
       "      <td>-*,***</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>99.87</td>\n",
       "      <td>2.61</td>\n",
       "      <td>10.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Step     Counts  Change Change (%) Retained (%)  \\\n",
       "0            Initial Rows  *,***,***      +0      +0.00       100.00   \n",
       "1       Remove Empty Rows  *,***,***      +0      +0.00       100.00   \n",
       "2  Remove Duplicated Rows  *,***,***     -**      -0.00       100.00   \n",
       "3   Remove Inactive Store  *,***,***  -*,***      -0.13        99.87   \n",
       "\n",
       "  Duration (s) Cumulative Time (s)  \n",
       "0         0.00                0.00  \n",
       "1         2.20                2.20  \n",
       "2         5.28                7.48  \n",
       "3         2.61               10.09  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary\n",
    "tracker_all_data.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4343f",
   "metadata": {},
   "source": [
    "# **Final Result**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da627b31",
   "metadata": {},
   "source": [
    "## **Save All Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c44f3dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 06:28:45 - __main__ - INFO - Saved *,***,*** rows to data\\clean\\df_all_data.csv (579.72 MB) in 19.19 secs\n"
     ]
    }
   ],
   "source": [
    "# save clean data\n",
    "output_file = os.path.join(config.DATA_PATH, \"clean\", \"df_all_data.csv\")\n",
    "\n",
    "start_time = time.time()\n",
    "df_all_data.to_csv(output_file, index=False)\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "file_size = os.path.getsize(output_file) / (1024**2) # in MB\n",
    "\n",
    "logger.info(f\"Saved {mask_numeric_value(f'{len(df_all_data):,}')} rows to {output_file[93:]} ({file_size:.2f} MB) in {load_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a20f08",
   "metadata": {},
   "source": [
    "## **Important Note**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c17b27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data has *,***,*** rows which is consist from **,*** unique OP and Store combinations\n"
     ]
    }
   ],
   "source": [
    "# show unique OP + store\n",
    "print(f\"All Data has {mask_numeric_value(f'{len(df_all_data):,}')} rows which is consist from {mask_numeric_value(f'{len(df_all_data[['OP', 'Toko']].drop_duplicates()):,}')} unique OP and Store combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a98bde",
   "metadata": {},
   "source": [
    "All Data contains:\n",
    "- **Total Rows**: \\*,\\*\\*\\*,\\*\\*\\* delivery records (SPJ)\n",
    "- **Unique OP and Store Combination**: \\*\\*,\\*\\*\\* stores\n",
    "\n",
    "This is important because each store may have multiple delivery records over time.\n",
    "\n",
    "Example:\n",
    "\n",
    "- Store 'ABCD' at OP 'OP1' might have **50 delivery records**\n",
    "- However, it still count as **1 unique store**\n",
    "\n",
    "<br>\n",
    "\n",
    "> For further analysis, this project will analyze at the **unique store** (unique OP and Store combination), not at **delivery records** (total rows) level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
